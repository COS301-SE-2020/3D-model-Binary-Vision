\# 3D Model Binary Vision Project
=================================

Team Landing Page:
==================

https://vanillav.github.io/FlapJacks.github.io/

A mobile web application that will allow a user to scan a physical
object and produce a 3 Dimensional model that can be viewed from any
direction. The user will also have the choice to build the model from
cameras moving sub sections of video. The videos will consist of SFM
clips. Once the model has been built, the user must be able to store
both the stereo-lithography as well as the surface information (such as
colouring). The user can select a stored model and generate a 3D render
on a Web Page, where they will be able to rotate the model.

Demo 1 Download: 
================
https://drive.google.com/file/d/1urvzRHTTUYAgFXoPAeqhKeeuAuu2Y3_j/view?usp=sharing 
-----------------------------------------------------------------------------------------------------------------
System Requirements Specification:
==================================
(pending) 
-----------------------------------------------------------------------------------------------------------------
Project Management:
====================
https://app.clubhouse.io/flapjacks301/stories/space/9/everything
-----------------------------------------------------------------------------------------------------------------
User Manual: 
=============
(pending) 
-----------------------------------------------------------------------------------------------------------------
Installation Instructions:
===========================

Must be tested on Linux.
MongoDB must be installed on the system.
Node must be installed on the system.

Download the master branch and unzip.

Open terminal in this location, type: node server.js

This will open the local host server on port 3000.

In your browser, go to localhost:3000/signup

Collaborators: 
=============== 
Rani Arraf: 
github.io:
https://raniarraf.github.io/

(Contribution): For Demo 1: Created the html and css for all pages, also
included some js to help with the integration between the signup/login
and the API. Created the forms for the signup and login. Revised over
the final analysis of the system functionality. 

Quinn du Piesanie: 
github.io: 
https://quinnman202.github.io/

(Contribution): Demo 1: Created simple javascript webGL program that renders verticies
that are passed to it. For documentation, I created a use-case diagram from retrieving
patient information and editing patients.

Jacobus Janse van Rensburg: 
github.io: 
https://jacobus1998.github.io/

(Contribution): For demo 1: Created the database and the Node.js API that 
connects the front and back end. I was part of the Integration process to 
integrate the front end and back end. For the documentation I did the Introduction, 
functional and quality requirements. I also set up the basic document that the
team then changed and inserted into as they seemed nescesary and what was assigned 
to them.

Steven Visser: 
github.io: 
https://vanillav.github.io/

(Contribution): For Demo 1: Created and managed the user stories using the project
management tools and set deadlines for work to be completed. Created the
Use Case Diagram for the Media & Render Subsystem. Revised the System
Requirements Specification Document and created Functional Requirements.
Implemented Unit Testing for the Signup operations with the API
integration.

Marcus Werren: 
github.io: 
https://marcuswerren.github.io/

(Contribution): For Demo 1: I created the tractability matrix for the documentation 
of the system. I implemented the Video capture functionality that allows the users 
to send a live recorded video or a pre-recorded video from the clients machine to 
back end for processing. I also contributed to the unit testing of the systems API calls.

End of README
